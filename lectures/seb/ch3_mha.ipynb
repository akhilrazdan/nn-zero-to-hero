{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18793c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raz/codespace/nn-zero-to-hero/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6941e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68119ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.1\n",
      "MPS available: True\n",
      "MPS built: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f559b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([0.43,0.19,0.89])\n",
    "x2 = torch.tensor([0.55,0.87,0.66]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4f87a",
   "metadata": {},
   "source": [
    "Goal is to write \n",
    "1. Simple\n",
    "2. Self (With trainable weights)\n",
    "    2.1. Scaled dot proeduct attention\n",
    "    2.2. Create a class\n",
    "    Exercise 3.1\n",
    "3.5 Causal \n",
    "    3.5.1 Causal attention mask\n",
    "    3.5.2 Add dropout\n",
    "    3.5.3. Causal attention class\n",
    "4. Multi-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16173bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [   [0.43, 0.15, 0.89],     # your\n",
    "        [0.55, 0.87, 0.66],     # journey\n",
    "        [0.57, 0.85, 0.64],     # starts\n",
    "        [0.22, 0.58, 0.33],     # with\n",
    "        [0.77, 0.25, 0.10],     # one\n",
    "        [0.05, 0.80, 0.55]]     # step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bde8491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = inputs[1]\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baed9424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores_1 = torch.zeros(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs): \n",
    "    attention_scores_1[i] = x2.dot(x_i)\n",
    "\n",
    "attention_scores_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d987a80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = inputs @  inputs.T # 6 x 3 3 x 6 = 6 x 6\n",
    "attn_scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cb33333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2241, 0.2140, 0.2113, 0.1066, 0.1026, 0.1415],\n",
       "        [0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656],\n",
       "        [0.1454, 0.2277, 0.2248, 0.1280, 0.1104, 0.1637],\n",
       "        [0.1304, 0.2313, 0.2275, 0.1354, 0.0953, 0.1801],\n",
       "        [0.1436, 0.2219, 0.2245, 0.1090, 0.2088, 0.0921],\n",
       "        [0.1350, 0.2325, 0.2269, 0.1405, 0.0628, 0.2022]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize using sum \n",
    "attn_weights = attn_scores / attn_scores.sum(dim=1, keepdim=True) \n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c41b1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize using softmax\n",
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "attn_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06513dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate context vectors \n",
    "context_vecs = attn_weights @ inputs # 6 x 6, 6 x 3\n",
    "context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c21f48ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing it with trainable weights\n",
    "torch.manual_seed(789)\n",
    "dim_in = 3\n",
    "dim_out = 2\n",
    "Wq = torch.randn(dim_in, dim_out, requires_grad=False)\n",
    "Wk = torch.randn(dim_in, dim_out, requires_grad=False)\n",
    "Wv = torch.randn(dim_in, dim_out, requires_grad=False)\n",
    "\n",
    "q = inputs @ Wq # 6 x 3 @ 3 x 2 6 x 2 \n",
    "k = inputs @ Wk\n",
    "v = inputs @ Wv\n",
    "\n",
    "attn_scores = q @ k.T # 6 x 2 @ 6 x 2 \n",
    "attn_wts = torch.softmax(attn_scores / k.shape[-1] ** 0.5, dim=1) # 6 x 6\n",
    "\n",
    "context_vecs = attn_wts @ v  #  6 x 6, 6 x 2 = \n",
    "k.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ae9356e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8073, -0.0946],\n",
       "        [-0.7652, -0.0935],\n",
       "        [-0.7697, -0.0930],\n",
       "        [-0.7786, -0.0966],\n",
       "        [-0.8164, -0.1016],\n",
       "        [-0.7326, -0.1010]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04296374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# ⚠️ What's the deal with not having bias in the initial layers\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.Wq = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.Wk = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.Wv = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x): \n",
    "        q = self.Wq(x) # 6 x 3 @ 3 x 2 6 x 2 \n",
    "        k = self.Wk(x)\n",
    "        v = self.Wv(x)\n",
    "\n",
    "        attn_scores = q @ k.T # 6 x 2 @ 6 x 2 \n",
    "        attn_wts = torch.softmax(attn_scores / k.shape[-1] ** 0.5, dim=1) # 6 x 6\n",
    "\n",
    "        context_vecs = attn_wts @ v  #  6 x 6, 6 x 2 = \n",
    "        return context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41895790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0739,  0.0713],\n",
       "        [-0.0748,  0.0703],\n",
       "        [-0.0749,  0.0702],\n",
       "        [-0.0760,  0.0685],\n",
       "        [-0.0763,  0.0679],\n",
       "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa = SelfAttention(dim_in, dim_out)\n",
    "sa.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d20dfb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.5 Causal attention\n",
    "context_length = 6\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe4cb74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3296, -0.1134, -0.0996, -0.0581,  0.1766, -0.1964],\n",
       "        [-0.9665, -0.2984, -0.2345, -0.2161,  0.9836, -0.8459],\n",
       "        [-0.9228, -0.2862, -0.2259, -0.2047,  0.9224, -0.7980],\n",
       "        [-0.6798, -0.2045, -0.1558, -0.1592,  0.7650, -0.6374],\n",
       "        [ 0.1251,  0.0156, -0.0085,  0.0589, -0.4413,  0.2915],\n",
       "        [-1.1313, -0.3323, -0.2457, -0.2758,  1.3832, -1.1245]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de81c83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3296,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.9665, -0.2984,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.9228, -0.2862, -0.2259,    -inf,    -inf,    -inf],\n",
       "        [-0.6798, -0.2045, -0.1558, -0.1592,    -inf,    -inf],\n",
       "        [ 0.1251,  0.0156, -0.0085,  0.0589, -0.4413,    -inf],\n",
       "        [-1.1313, -0.3323, -0.2457, -0.2758,  1.3832, -1.1245]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1e46dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2., 2.]])\n",
      "tensor([[0., 0., 0., 4., 4., 0.],\n",
      "        [4., 0., 0., 4., 0., 4.],\n",
      "        [0., 0., 4., 0., 4., 0.],\n",
      "        [4., 4., 0., 4., 4., 0.],\n",
      "        [4., 0., 0., 0., 4., 4.],\n",
      "        [4., 4., 4., 0., 0., 4.]])\n"
     ]
    }
   ],
   "source": [
    "test = torch.ones((context_length, context_length))\n",
    "test += 1\n",
    "print(test)\n",
    "dropout = nn.Dropout(0.5)\n",
    "print(dropout(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c3c34871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module): \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_biases=False):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.wk = nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.wv = nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask', \n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        b, num_tokens, d_in = x.shape\n",
    "        q = self.wq(x) # b, T, d_out\n",
    "        v = self.wv(x)\n",
    "        k = self.wk(x)\n",
    "\n",
    "        attn_scores = q @ k.transpose(1, 2)  # b t dout - b t dout = b t t \n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / k.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = attn_weights @ v # b t t, b t c\n",
    "        return context_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "227ce5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9038,  0.4432],\n",
       "         [-0.4368,  0.2142],\n",
       "         [-0.4849, -0.1341],\n",
       "         [-0.5834,  0.0081],\n",
       "         [-0.6219, -0.0526],\n",
       "         [-0.1417, -0.0505]],\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [-1.1749,  0.0116],\n",
       "         [-0.7733,  0.0073],\n",
       "         [-0.9140, -0.2769],\n",
       "         [-0.7679, -0.0735],\n",
       "         [-0.6749, -0.0984]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "ca = CausalAttention(d_in=dim_in, d_out=dim_out, context_length=6, dropout=0.5)\n",
    "inp = torch.stack((inputs, inputs), dim=0)\n",
    "out = ca(inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bae69a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module): \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, n_heads, qkv_biases=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_biases) for head in range(n_heads)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ce85f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 4])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma = MultiHeadAttentionWrapper(dim_in, dim_out, context_length, 0.5, n_heads=2)\n",
    "out = ma.forward(inp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "62f2bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module): \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, n_heads, qkv_biases=False):\n",
    "        super().__init__()\n",
    "        if d_out % n_heads != 0: \n",
    "            raise ValueError(\"Please make it divisible\")\n",
    "        \n",
    "        self.n_heads = n_heads\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // n_heads\n",
    "\n",
    "        self.Wq = nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.Wk = nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.Wv = nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer(\n",
    "            'mask', \n",
    "            torch.triu(torch.ones((context_length, context_length)), diagonal=1)\n",
    "        )\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "\n",
    "    def forward(self, x): \n",
    "        b, t, d_in = x.shape\n",
    "                \n",
    "        q = self.Wq(x) # b, t, d_out\n",
    "        k = self.Wk(x)\n",
    "        v = self.Wv(x) # b, t, c\n",
    "\n",
    "        q = q.view(b, t, self.n_heads, self.head_dim) # b, t, n_head, head_dim\n",
    "        k = k.view(b, t, self.n_heads, self.head_dim)\n",
    "        v = v.view(b, t, self.n_heads, self.head_dim)\n",
    "\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2) # b, n_head, t, head_dim\n",
    "        print(q.shape, k.shape, v.shape)\n",
    "\n",
    "        attn_scores = q @ k.transpose(2, 3) # b, n_head, t, head_dim @ b, n_head, head_dim, t\n",
    "        attn_scores.masked_fill_(\n",
    "            mask.bool()[:t, :t], -torch.inf\n",
    "        )\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        context_vec = (attn_weights @ v).transpose(1,2) # b, n_head, t, t @ b, n_head, t, head_dim = b, n_head, t, head_dim\n",
    "        print(context_vec.shape, self.d_out)\n",
    "        context_vec = context_vec.contiguous().view(b, t, self.d_out)\n",
    "\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ab2d3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c26ea8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 6, 1]) torch.Size([2, 2, 6, 1]) torch.Size([2, 2, 6, 1])\n",
      "torch.Size([2, 6, 2, 1]) 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "mha = MultiHeadAttention(dim_in, dim_out, context_length, 0.5, 2, qkv_biases=False)\n",
    "out = mha(inp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "92c3f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3190, 0.4858],\n",
       "         [0.2943, 0.3897],\n",
       "         [0.2856, 0.3593],\n",
       "         [0.2693, 0.3873],\n",
       "         [0.2639, 0.3928],\n",
       "         [0.2575, 0.4028]],\n",
       "\n",
       "        [[0.3190, 0.4858],\n",
       "         [0.2943, 0.3897],\n",
       "         [0.2856, 0.3593],\n",
       "         [0.2693, 0.3873],\n",
       "         [0.2639, 0.3928],\n",
       "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc8226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn-zero-to-hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
